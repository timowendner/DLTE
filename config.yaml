train folder: 'trainset'
prediction folder: 'testset'
label file: 'trainset/key-meter_train_gt.txt'
output file: output/outputs.txt


train split: 0.8
learning rate: 0.0001
train epochs: 50
batch size: 16
Data Length: 350
Dropout: 0.25

# compute the n-order differences for the starting points.
# meaning the differences for the first values to the second.
# first order differences for [1, 2, 4, 5] is [0, 1, 2, 1]
n order differences: 36

# write the predictions every n iteration.
# this is done because the prediction is costly
write every n iteration: 10

# for every prediction (and testing) compute n predictions and
# get the mean of those predictions.
check n times: 10

# the model class: 'CNN', 'RNN'
model class: 'CNN'

# settings for the CNN
kernel size: 5
CNN features: [200, 400, 450, 400, 400, 200]
Output features: [500, 200, 1]

# settings for the RNN
bidirectional: False
hidden size: 500

# use the debug size for only loading 20 files instead of the
# whole dataset. (comment out if using the whole dataset)
# debug size: 20